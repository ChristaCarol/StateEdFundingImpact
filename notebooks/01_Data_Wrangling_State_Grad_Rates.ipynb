{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54f89a8",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"font-size:28px; font-weight:bold;\">Concatenating Annual Datasets into a Single DataFrame</div>\n",
    "\n",
    "This Jupyter Notebook serves as a foundation for an in-depth analysis of educational outcomes and state funding correlations. By consolidating EDFacts datasets from 2015 to 2021 into a single DataFrame, it enables a streamlined approach to examining trends and performing comprehensive analyses. This preparatory step is crucial for the subsequent project titled \"Educate, Invest, Excel: Budgets & StateEd Priorities,\" which aims to dissect the nuanced relationship between state funding allocations and academic achievements in early education. This endeavor not only seeks to identify the impact of financial investments in education but also to provide actionable insights for enhancing educational quality through strategic funding. By merging these datasets, we lay the groundwork for a detailed exploration of how different states' budgetary priorities influence educational outcomes, thereby offering valuable evidence-based recommendations for policymakers and educational stakeholders.\n",
    "<br></br>\n",
    "<div align=\"center\" style=\"font-size:20px; font-weight:bold;\">Data Processing and Analysis Workflow</div>\n",
    "\n",
    "#### Data Extraction:\n",
    "Initiate the project by extracting data from EDFacts, specifically targeting the LEA (Local Education Agency) files for each school year. While the School Level data offers granular insights, the LEA files provide a more aggregated view, suitable for analyzing trends and outcomes at a broader, district-wide level. Accompanying 'Documentation' and 'Data Notes' files will be reviewed to understand any nuances or specific considerations that may influence our analysis, ensuring we account for any anomalies or significant changes in data collection methodologies over the years.\n",
    "#### Data Cleaning:\n",
    "The next phase involves meticulously cleaning the extracted data to ensure uniformity and accuracy across all datasets. This step is crucial for aligning column names, addressing missing or incomplete data, and verifying that all data types are correctly formatted for subsequent analysis. The goal is to create a consistent and reliable dataset that accurately reflects the LEA's educational outcomes and characteristics over time.\n",
    "#### Data Concatenation:\n",
    "Following cleaning, we will concatenate the annual datasets into a singular, comprehensive DataFrame. This consolidation is pivotal for facilitating longitudinal studies, allowing us to observe and analyze trends, shifts, and patterns in educational outcomes across different time periods. By amalgamating the data, we lay the groundwork for a robust analysis that can uncover insights into the effectiveness of educational policies and funding allocations at the LEA level.\n",
    "#### Analysis Preparation:\n",
    "With a concatenated DataFrame in hand, we'll undertake preparatory steps to ready the data for in-depth analysis. This includes setting proper indices, ensuring the data is correctly sorted, and conducting final integrity and consistency checks. This preparation is essential for a seamless analysis phase, where we aim to delve into the intricate relationships between state funding, educational initiatives, and academic success rates.\n",
    "\n",
    "Original datasets were found here: https://www2.ed.gov/about/inits/ed/edfacts/data-files/index.html#acgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a7a4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\StateEdFundingImpact\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\user\\Desktop\\StateEdFundingImpact\"\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0a0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.extract_data import extract_data\n",
    "from src.data.clean_data import flatten_columns_and_rename\n",
    "from src.data.clean_pre_18 import clean_pre_18\n",
    "from src.data.clean_post_18 import clean_post_18\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b9c7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     STNAM  FIPST   LEAID             LEANM  ALL_COHORT_1516 ALL_RATE_1516  \\\n",
      "0  ALABAMA      1  100005  Albertville City              296            92   \n",
      "1  ALABAMA      1  100006   Marshall County              434            88   \n",
      "2  ALABAMA      1  100007       Hoover City             1127            93   \n",
      "3  ALABAMA      1  100008      Madison City              855            97   \n",
      "4  ALABAMA      1  100011        Leeds City              123         90-94   \n",
      "\n",
      "   MAM_COHORT_1516 MAM_RATE_1516  MAS_COHORT_1516 MAS_RATE_1516  ...  \\\n",
      "0              2.0            PS              1.0            PS  ...   \n",
      "1              4.0            PS              1.0            PS  ...   \n",
      "2              NaN           NaN             65.0         90-94  ...   \n",
      "3              3.0            PS             63.0          GE95  ...   \n",
      "4              NaN           NaN              1.0            PS  ...   \n",
      "\n",
      "   MTR_RATE_1516 MWH_COHORT_1516  MWH_RATE_1516 CWD_COHORT_1516  \\\n",
      "0            NaN           193.0          90-94            18.0   \n",
      "1             PS           368.0             86            51.0   \n",
      "2           GE80           678.0             96            82.0   \n",
      "3           GE80           534.0             98            47.0   \n",
      "4             PS            66.0           GE95            16.0   \n",
      "\n",
      "   CWD_RATE_1516 ECD_COHORT_1516  ECD_RATE_1516 LEP_COHORT_1516  \\\n",
      "0          60-79           108.0          80-84             9.0   \n",
      "1          50-59           274.0          80-84             3.0   \n",
      "2          60-64           223.0          80-84             8.0   \n",
      "3          70-79           162.0          90-94             7.0   \n",
      "4          60-79            60.0          80-89             1.0   \n",
      "\n",
      "   LEP_RATE_1516 DATE_CUR  \n",
      "0           GE50  01JUL17  \n",
      "1             PS  01JUL17  \n",
      "2           GE50  01JUL17  \n",
      "3           GE50  01JUL17  \n",
      "4             PS  01JUL17  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "     STNAM  FIPST   LEAID ST_LEAID             LEANM  ALL_COHORT_1617  \\\n",
      "0  ALABAMA      1  100005   AL-101  Albertville City              311   \n",
      "1  ALABAMA      1  100006   AL-048   Marshall County              431   \n",
      "2  ALABAMA      1  100007   AL-158       Hoover City             1153   \n",
      "3  ALABAMA      1  100008   AL-169      Madison City              861   \n",
      "4  ALABAMA      1  100011   AL-167        Leeds City              110   \n",
      "\n",
      "  ALL_RATE_1617  MAM_COHORT_1617 MAM_RATE_1617  MAS_COHORT_1617  ...  \\\n",
      "0            93              NaN           NaN              2.0  ...   \n",
      "1            90              NaN           NaN              1.0  ...   \n",
      "2            93              NaN           NaN             60.0  ...   \n",
      "3            97              NaN           NaN             60.0  ...   \n",
      "4          GE95              NaN           NaN              1.0  ...   \n",
      "\n",
      "  MTR_RATE_1617  MWH_COHORT_1617 MWH_RATE_1617  CWD_COHORT_1617 CWD_RATE_1617  \\\n",
      "0            PS            199.0         90-94              NaN           NaN   \n",
      "1            PS            356.0            90              NaN           NaN   \n",
      "2          GE90            682.0            95              NaN           NaN   \n",
      "3          GE80            544.0            97              NaN           NaN   \n",
      "4          GE50             55.0         80-89              NaN           NaN   \n",
      "\n",
      "   ECD_COHORT_1617 ECD_RATE_1617  LEP_COHORT_1617 LEP_RATE_1617  DATE_CUR  \n",
      "0              NaN           NaN              NaN           NaN   17AUG18  \n",
      "1              NaN           NaN              NaN           NaN   17AUG18  \n",
      "2              NaN           NaN              NaN           NaN   17AUG18  \n",
      "3              NaN           NaN              NaN           NaN   17AUG18  \n",
      "4              NaN           NaN              NaN           NaN   17AUG18  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "     STNAM  FIPST   LEAID ST_LEAID             LEANM  ALL_COHORT_1718  \\\n",
      "0  ALABAMA      1  100005   AL-101  Albertville City              312   \n",
      "1  ALABAMA      1  100006   AL-048   Marshall County              416   \n",
      "2  ALABAMA      1  100007   AL-158       Hoover City             1120   \n",
      "3  ALABAMA      1  100008   AL-169      Madison City              923   \n",
      "4  ALABAMA      1  100011   AL-167        Leeds City              128   \n",
      "\n",
      "  ALL_RATE_1718  MAM_COHORT_1718 MAM_RATE_1718  MAS_COHORT_1718  ...  \\\n",
      "0            94              NaN           NaN              2.0  ...   \n",
      "1            91              3.0            PS              3.0  ...   \n",
      "2            94              NaN           NaN             73.0  ...   \n",
      "3            96              3.0            PS             76.0  ...   \n",
      "4          GE95              NaN           NaN              2.0  ...   \n",
      "\n",
      "  CWD_RATE_1718  ECD_COHORT_1718 ECD_RATE_1718  FCS_COHORT_1718 FCS_RATE_1718  \\\n",
      "0          GE50             93.0         80-84              NaN           NaN   \n",
      "1         70-79            249.0         85-89              2.0            PS   \n",
      "2         60-69            234.0         80-84              2.0            PS   \n",
      "3         75-79            159.0         85-89              1.0            PS   \n",
      "4          GE50             53.0          GE90              1.0            PS   \n",
      "\n",
      "   HOM_COHORT_1718 HOM_RATE_1718  LEP_COHORT_1718 LEP_RATE_1718  DATE_CUR  \n",
      "0              2.0            PS             22.0         60-79   23SEP19  \n",
      "1             23.0          GE80             11.0          GE50   23SEP19  \n",
      "2              7.0          GE50              9.0          LT50   23SEP19  \n",
      "3              9.0          GE50             13.0          GE50   23SEP19  \n",
      "4              4.0            PS              1.0            PS   23SEP19  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "  SCHOOL_YEAR    STNAM  FIPST   LEAID ST_LEAID             LEANM CATEGORY  \\\n",
      "0   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      ALL   \n",
      "1   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      CWD   \n",
      "2   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      ECD   \n",
      "3   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      HOM   \n",
      "4   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      LEP   \n",
      "\n",
      "   COHORT   RATE DATE_CUR  \n",
      "0     375     94  24JUL20  \n",
      "1      19   GE80  24JUL20  \n",
      "2     114  90-94  24JUL20  \n",
      "3       7   LT50  24JUL20  \n",
      "4      67  75-79  24JUL20  \n",
      "  SCHOOL_YEAR    STNAM  FIPST   LEAID ST_LEAID             LEANM CATEGORY  \\\n",
      "0   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      ALL   \n",
      "1   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      CWD   \n",
      "2   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      ECD   \n",
      "3   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      FCS   \n",
      "4   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      HOM   \n",
      "\n",
      "   COHORT   RATE DATE_CUR  \n",
      "0     347     93  19MAY21  \n",
      "1      20  60-79  19MAY21  \n",
      "2      97  90-94  19MAY21  \n",
      "3       2     PS  19MAY21  \n",
      "4       2     PS  19MAY21  \n",
      "  SCHOOL_YEAR    STNAM  FIPST   LEAID ST_LEAID             LEANM CATEGORY  \\\n",
      "0   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      ALL   \n",
      "1   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      CWD   \n",
      "2   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      ECD   \n",
      "3   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      HOM   \n",
      "4   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      LEP   \n",
      "\n",
      "   COHORT   RATE DATE_CUR  \n",
      "0     385     93  25MAY22  \n",
      "1      20  60-79  25MAY22  \n",
      "2     174  90-94  25MAY22  \n",
      "3       2     PS  25MAY22  \n",
      "4      57  80-89  25MAY22  \n"
     ]
    }
   ],
   "source": [
    "#Extracting\n",
    "# src/data/extract_data.py\n",
    "\n",
    "def extract_data(file_paths):\n",
    "    \"\"\"Extract data from multiple CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    - file_paths (list of str): A list of paths to the CSV files.\n",
    "\n",
    "    Returns:\n",
    "    - list of pd.DataFrame: A list of the extracted data as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    dataframes = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "    return dataframes\n",
    "\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2015-16.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2016-17.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2017-18.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2018-19-long.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2019-20-long.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2020-21-long.csv\"\n",
    "]\n",
    "dfs = extract_data(file_paths)\n",
    "\n",
    "for df in dfs:\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21052501",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<body>\n",
    "<h1 style=\"text-align: center;\">Streamlined Approach to Cleaning Educational Data</h1>\n",
    "\n",
    "<h3>Overview</h3>\n",
    "<p>In preparing the EDFacts educational data for comprehensive analysis, our approach was guided by the goal of ensuring data usability and integrity across all available years. Contrary to initial expectations, the distinction between pre-2018 and post-2018 datasets did not necessitate a significantly bifurcated cleaning strategy. Instead, we implemented a streamlined process that effectively addressed the nuances of the entire dataset, reinforcing our commitment to analytical precision and data consistency.</p>\n",
    "\n",
    "<h3>Key Steps in Data Preparation</h3>\n",
    "\n",
    "<strong>Data Extraction and Transformation:</strong>\n",
    "<p>Our first step involved extracting essential information and transforming the data into a long format, which enhanced our ability to manipulate and analyze the information at a granular level. This transformation was crucial for simplifying the datasets into a manageable structure conducive to in-depth examination.</p>\n",
    "\n",
    "<strong>Normalization and Aggregation:</strong>\n",
    "<p>We normalized rate data, converting various representations into a standardized numeric format to address the presence of rate ranges and specific codes. This uniformity allowed for comparative analyses across different states. Additionally, we aggregated the data by state, summarizing cohort sizes and average graduation rates, which was instrumental in comparing educational outcomes and understanding trends and patterns.</p>\n",
    "\n",
    "<h3>Consistent Cleaning Logic Across Years</h3>\n",
    "<p>Despite initial plans for a two-phase approach due to anticipated variations in data structure and reporting standards post-2018, our cleaning process remained largely consistent across all years. The minor adjustments made for post-2018 data did not significantly alter our overall strategy, allowing us to maintain a uniform analytical framework. This consistency ensures that our analysis is based on harmonized datasets, enabling us to draw meaningful insights into the impact of state funding and other factors on graduation outcomes—a key measure of educational success.</p>\n",
    "\n",
    "<h3>Conclusion</h3>\n",
    "<p>Our streamlined data cleaning process underscores the importance of flexibility and precision in handling educational data. By adapting our methodologies to the characteristics of the dataset as a whole, rather than imposing arbitrary divisions, we have laid a robust foundation for subsequent analyses. This approach allows us to explore the evolving landscape of educational data with an analytical lens that is both comprehensive and current, ensuring that our insights remain relevant and actionable.</p>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce6f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the specified file paths\n",
    "state_grads_dataframes = extract_data(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8309450",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs_2015_2021 = [clean_pre_18(df) if index < 3 else clean_post_18(df) for index, df in enumerate(dfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf7e1cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         52 non-null     object \n",
      " 1   COHORT        52 non-null     object \n",
      " 2   PERCENT_RATE  52 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n",
      "\n",
      "\n",
      "DataFrame 1:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         50 non-null     object \n",
      " 1   COHORT        50 non-null     object \n",
      " 2   PERCENT_RATE  50 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n",
      "\n",
      "\n",
      "DataFrame 2:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         52 non-null     object \n",
      " 1   COHORT        52 non-null     object \n",
      " 2   PERCENT_RATE  52 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n",
      "\n",
      "\n",
      "DataFrame 3:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51 entries, 2018-2019 to 2018-2019\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         51 non-null     object \n",
      " 1   COHORT        51 non-null     int64  \n",
      " 2   RATE_NUMERIC  51 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.6+ KB\n",
      "\n",
      "\n",
      "DataFrame 4:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51 entries, 2019-2020 to 2019-2020\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         51 non-null     object \n",
      " 1   COHORT        51 non-null     int64  \n",
      " 2   RATE_NUMERIC  51 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.6+ KB\n",
      "\n",
      "\n",
      "DataFrame 5:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50 entries, 2020-2021 to 2020-2021\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         50 non-null     object \n",
      " 1   COHORT        50 non-null     int64  \n",
      " 2   RATE_NUMERIC  50 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.6+ KB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking clean\n",
    "for index, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    print(f\"DataFrame {index}:\")\n",
    "    df.info()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54cb78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0 head:\n",
      "DATA_TYPE                       STATE    COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                  \n",
      "2015-16                       ALABAMA  145983.0     76.378635\n",
      "2015-16                        ALASKA   25039.0     62.145089\n",
      "2015-16                       ARIZONA  202193.0     65.798584\n",
      "2015-16                      ARKANSAS   94906.0     76.651163\n",
      "2015-16      BUREAU OF INDIAN AFFAIRS    6772.0     69.043814 \n",
      "\n",
      "DataFrame 1 head:\n",
      "DATA_TYPE                       STATE    COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                  \n",
      "2016-17                       ALABAMA  110458.0     81.771401\n",
      "2016-17                        ALASKA   25788.0     63.026316\n",
      "2016-17                       ARIZONA  204878.0     64.633005\n",
      "2016-17                      ARKANSAS  100439.0     77.265913\n",
      "2016-17      BUREAU OF INDIAN AFFAIRS    9163.0     58.681579 \n",
      "\n",
      "DataFrame 2 head:\n",
      "DATA_TYPE                         STATE    COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                    \n",
      "2017-18                         ALABAMA  141949.0     77.201247\n",
      "2017-18                          ALASKA   26634.0     63.012245\n",
      "2017-18                         ARIZONA  217413.0     65.936614\n",
      "2017-18                        ARKANSAS  102892.0     75.852765\n",
      "2017-18      BUREAU OF INDIAN EDUCATION    9634.0     59.637056 \n",
      "\n",
      "DataFrame 3 head:\n",
      "                                  STATE  COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                  \n",
      "2018-2019                       ALABAMA  133900     78.639080\n",
      "2018-2019                        ALASKA   26166     64.489540\n",
      "2018-2019                       ARIZONA  220323     65.405128\n",
      "2018-2019                      ARKANSAS  107551     74.131542\n",
      "2018-2019    BUREAU OF INDIAN EDUCATION    8966     60.745238 \n",
      "\n",
      "DataFrame 4 head:\n",
      "                                  STATE  COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                  \n",
      "2019-2020                       ALABAMA  136374     78.251689\n",
      "2019-2020                        ALASKA   25445     64.143154\n",
      "2019-2020                       ARIZONA  230145     64.288913\n",
      "2019-2020                      ARKANSAS  109168     74.784965\n",
      "2019-2020    BUREAU OF INDIAN EDUCATION    9410     61.677249 \n",
      "\n",
      "DataFrame 5 head:\n",
      "                  STATE   COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                   \n",
      "2020-2021       ALABAMA   134727     78.340782\n",
      "2020-2021        ALASKA    24658     63.096234\n",
      "2020-2021       ARIZONA   229510     63.609646\n",
      "2020-2021      ARKANSAS   105360     74.467483\n",
      "2020-2021    CALIFORNIA  1285025     75.479113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "school_years_pre_18 = ['2015-16', '2016-17', '2017-18']\n",
    "\n",
    "for index, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    if index < 3:  # For pre-2018 DataFrames\n",
    "        df['SCHOOL_YEAR'] = school_years_pre_18[index]\n",
    "\n",
    "        # setting school year as index for 2015-2017 school years to match post 2018 sy's\n",
    "\n",
    "for i in range(3):  # This targets only the first three DataFrames\n",
    "    # Assuming 'SCHOOL_YEAR' is a column that needs to be set as the index for these DataFrames\n",
    "    cleaned_dfs_2015_2021[i].set_index('SCHOOL_YEAR', inplace=True)\n",
    "\n",
    "# making sure column names match for post 2018\n",
    "for i, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    # Check if 'RATE_NUMERIC' column exists in the DataFrame\n",
    "    if 'RATE_NUMERIC' in df.columns:\n",
    "        # Rename 'RATE_NUMERIC' to 'PERCENT_RATE'\n",
    "        df.rename(columns={'RATE_NUMERIC': 'PERCENT_RATE'}, inplace=True)\n",
    "\n",
    "\n",
    "for index, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    print(f\"DataFrame {index} head:\")\n",
    "    print(df.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74ace12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 1 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 2 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 3 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 4 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 5 is clean of BUREAU OF INDIAN EDUCATION\n"
     ]
    }
   ],
   "source": [
    "# dropping Bureau of Indian Education since there is not information for SY 2020-2021\n",
    "cleaned_dfs_2015_2021 = [\n",
    "    df.query(\"STATE != 'BUREAU OF INDIAN EDUCATION'\") \n",
    "    if 'STATE' in df.columns else df  # Check if 'STATE' column exists to avoid KeyError\n",
    "    for df in cleaned_dfs_2015_2021\n",
    "]\n",
    "for index, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    if 'STATE' in df.columns and 'BUREAU OF INDIAN EDUCATION' in df['STATE'].values:\n",
    "        print(f\"BUREAU OF INDIAN EDUCATION exists in DataFrame {index}\")\n",
    "    else:\n",
    "        print(f\"DataFrame {index} is clean of BUREAU OF INDIAN EDUCATION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37353f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 1 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 2 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 3 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 4 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 5 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    print(f\"DataFrame {i} columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb115e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    \"\"\"\n",
    "    Renames columns in each DataFrame within cleaned_dfs_2015_2021 to include the full school year in their names.\n",
    "\n",
    "    This loop iterates through each DataFrame in the cleaned_dfs_2015_2021 list. For each DataFrame, it calculates the\n",
    "    start and end years based on the index and a base year of 2015. It then renames the 'COHORT' and 'PERCENT_RATE'\n",
    "    columns to 'Cohort_{start_year}_{end_year}' and 'Rate_{start_year}_{end_year}', respectively, to reflect the\n",
    "    specific school year the data pertains to. The renaming is done in-place, updating each DataFrame within the list.\n",
    "\n",
    "    Parameters:\n",
    "    - i: Index of the current DataFrame in the cleaned_dfs_2015_2021 list.\n",
    "    - df: The current DataFrame being processed.\n",
    "\n",
    "    Returns:\n",
    "    - None. The function directly modifies the DataFrames in the cleaned_dfs_2015_2021 list.\n",
    "    \"\"\"\n",
    "    start_year = 2015 + i\n",
    "    end_year = start_year + 1  # To get the format like 2015_2016\n",
    "    df.rename(columns={'COHORT': f'Cohort_{start_year}_{end_year}', 'PERCENT_RATE': f'Rate_{start_year}_{end_year}'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b504e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Cohort_2015_2016  Rate_2015_2016 Cohort_2016_2017  Rate_2016_2017  \\\n",
      "STATE                                                                          \n",
      "ALABAMA            145983.0       76.378635         110458.0       81.771401   \n",
      "ALASKA              25039.0       62.145089          25788.0       63.026316   \n",
      "ARIZONA            202193.0       65.798584         204878.0       64.633005   \n",
      "ARKANSAS            94906.0       76.651163         100439.0       77.265913   \n",
      "CALIFORNIA        1305135.0       76.375773        1256965.0       76.089526   \n",
      "\n",
      "           Cohort_2017_2018  Rate_2017_2018  Cohort_2018_2019  Rate_2018_2019  \\\n",
      "STATE                                                                           \n",
      "ALABAMA            141949.0       77.201247          133900.0       78.639080   \n",
      "ALASKA              26634.0       63.012245           26166.0       64.489540   \n",
      "ARIZONA            217413.0       65.936614          220323.0       65.405128   \n",
      "ARKANSAS           102892.0       75.852765          107551.0       74.131542   \n",
      "CALIFORNIA        1312181.0       74.947489         1291970.0       75.708344   \n",
      "\n",
      "            Cohort_2019_2020  Rate_2019_2020  Cohort_2020_2021  Rate_2020_2021  \n",
      "STATE                                                                           \n",
      "ALABAMA             136374.0       78.251689          134727.0       78.340782  \n",
      "ALASKA               25445.0       64.143154           24658.0       63.096234  \n",
      "ARIZONA             230145.0       64.288913          229510.0       63.609646  \n",
      "ARKANSAS            109168.0       74.784965          105360.0       74.467483  \n",
      "CALIFORNIA         1285366.0       75.111411         1285025.0       75.479113  \n"
     ]
    }
   ],
   "source": [
    "def merge_dataframes(cleaned_dfs):\n",
    "    \"\"\"\n",
    "    Merges a list of DataFrames into a single DataFrame.\n",
    "\n",
    "    This function initializes the merged DataFrame with the first DataFrame in the provided list.\n",
    "    It then iteratively merges each subsequent DataFrame into this initial DataFrame based on the 'STATE' column.\n",
    "    The merge is done using an outer join to ensure all data from each state is retained, even if some states\n",
    "    are missing from some DataFrames. The result is a comprehensive DataFrame that combines all the provided\n",
    "    DataFrames' information.\n",
    "\n",
    "    Parameters:\n",
    "    - cleaned_dfs (list of pd.DataFrame): A list of cleaned DataFrames ready to be merged. Each DataFrame\n",
    "      must contain a 'STATE' column as the key for merging.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A single DataFrame resulting from the outer merge of all DataFrames in the input list.\n",
    "    \"\"\"\n",
    "    merged_state_grads_df = cleaned_dfs[0]\n",
    "\n",
    "    for df in cleaned_dfs[1:]:\n",
    "        merged_state_grads_df = pd.merge(merged_state_grads_df, df, on=\"STATE\", how=\"outer\")\n",
    "\n",
    "    # Set 'STATE' column as index\n",
    "    merged_state_grads_df.set_index('STATE', inplace=True)\n",
    "\n",
    "    return merged_state_grads_df\n",
    "\n",
    "# Usage\n",
    "merged_state_grads_df = merge_dataframes(cleaned_dfs_2015_2021)\n",
    "\n",
    "# Filtering out \"Bureau of Indian Affairs\"\n",
    "merged_state_grads_df = merged_state_grads_df[merged_state_grads_df.index != 'BUREAU OF INDIAN AFFAIRS']\n",
    "\n",
    "# Print to see if everything looks good\n",
    "print(merged_state_grads_df.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
