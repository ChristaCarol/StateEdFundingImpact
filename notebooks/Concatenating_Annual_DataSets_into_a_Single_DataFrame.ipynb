{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54f89a8",
   "metadata": {},
   "source": [
    "<div align=\"center\" style=\"font-size:28px; font-weight:bold;\">Concatenating Annual Datasets into a Single DataFrame</div>\n",
    "\n",
    "This Jupyter Notebook serves as a foundation for an in-depth analysis of educational outcomes and state funding correlations. By consolidating EDFacts datasets from 2015 to 2021 into a single DataFrame, it enables a streamlined approach to examining trends and performing comprehensive analyses. This preparatory step is crucial for the subsequent project titled \"Educate, Invest, Excel: Budgets & StateEd Priorities,\" which aims to dissect the nuanced relationship between state funding allocations and academic achievements in early education. This endeavor not only seeks to identify the impact of financial investments in education but also to provide actionable insights for enhancing educational quality through strategic funding. By merging these datasets, we lay the groundwork for a detailed exploration of how different states' budgetary priorities influence educational outcomes, thereby offering valuable evidence-based recommendations for policymakers and educational stakeholders.\n",
    "<br></br>\n",
    "<div align=\"center\" style=\"font-size:20px; font-weight:bold;\">Data Processing and Analysis Workflow</div>\n",
    "\n",
    "#### Data Extraction:\n",
    "Initiate the project by extracting data from EDFacts, specifically targeting the LEA (Local Education Agency) files for each school year. While the School Level data offers granular insights, the LEA files provide a more aggregated view, suitable for analyzing trends and outcomes at a broader, district-wide level. Accompanying 'Documentation' and 'Data Notes' files will be reviewed to understand any nuances or specific considerations that may influence our analysis, ensuring we account for any anomalies or significant changes in data collection methodologies over the years.\n",
    "#### Data Cleaning:\n",
    "The next phase involves meticulously cleaning the extracted data to ensure uniformity and accuracy across all datasets. This step is crucial for aligning column names, addressing missing or incomplete data, and verifying that all data types are correctly formatted for subsequent analysis. The goal is to create a consistent and reliable dataset that accurately reflects the LEA's educational outcomes and characteristics over time.\n",
    "#### Data Concatenation:\n",
    "Following cleaning, we will concatenate the annual datasets into a singular, comprehensive DataFrame. This consolidation is pivotal for facilitating longitudinal studies, allowing us to observe and analyze trends, shifts, and patterns in educational outcomes across different time periods. By amalgamating the data, we lay the groundwork for a robust analysis that can uncover insights into the effectiveness of educational policies and funding allocations at the LEA level.\n",
    "#### Analysis Preparation:\n",
    "With a concatenated DataFrame in hand, we'll undertake preparatory steps to ready the data for in-depth analysis. This includes setting proper indices, ensuring the data is correctly sorted, and conducting final integrity and consistency checks. This preparation is essential for a seamless analysis phase, where we aim to delve into the intricate relationships between state funding, educational initiatives, and academic success rates.\n",
    "\n",
    "Original datasets were found here: https://www2.ed.gov/about/inits/ed/edfacts/data-files/index.html#acgr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a7a4f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Desktop\\StateEdFundingImpact\n"
     ]
    }
   ],
   "source": [
    "%cd \"C:\\Users\\user\\Desktop\\StateEdFundingImpact\"\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b0a0bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.extract_data import extract_data\n",
    "from src.data.clean_data import flatten_columns_and_rename\n",
    "from src.data.clean_pre_18 import clean_pre_18\n",
    "from src.data.clean_post_18 import clean_post_18\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4b9c7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     STNAM  FIPST   LEAID             LEANM  ALL_COHORT_1516 ALL_RATE_1516  \\\n",
      "0  ALABAMA      1  100005  Albertville City              296            92   \n",
      "1  ALABAMA      1  100006   Marshall County              434            88   \n",
      "2  ALABAMA      1  100007       Hoover City             1127            93   \n",
      "3  ALABAMA      1  100008      Madison City              855            97   \n",
      "4  ALABAMA      1  100011        Leeds City              123         90-94   \n",
      "\n",
      "   MAM_COHORT_1516 MAM_RATE_1516  MAS_COHORT_1516 MAS_RATE_1516  ...  \\\n",
      "0              2.0            PS              1.0            PS  ...   \n",
      "1              4.0            PS              1.0            PS  ...   \n",
      "2              NaN           NaN             65.0         90-94  ...   \n",
      "3              3.0            PS             63.0          GE95  ...   \n",
      "4              NaN           NaN              1.0            PS  ...   \n",
      "\n",
      "   MTR_RATE_1516 MWH_COHORT_1516  MWH_RATE_1516 CWD_COHORT_1516  \\\n",
      "0            NaN           193.0          90-94            18.0   \n",
      "1             PS           368.0             86            51.0   \n",
      "2           GE80           678.0             96            82.0   \n",
      "3           GE80           534.0             98            47.0   \n",
      "4             PS            66.0           GE95            16.0   \n",
      "\n",
      "   CWD_RATE_1516 ECD_COHORT_1516  ECD_RATE_1516 LEP_COHORT_1516  \\\n",
      "0          60-79           108.0          80-84             9.0   \n",
      "1          50-59           274.0          80-84             3.0   \n",
      "2          60-64           223.0          80-84             8.0   \n",
      "3          70-79           162.0          90-94             7.0   \n",
      "4          60-79            60.0          80-89             1.0   \n",
      "\n",
      "   LEP_RATE_1516 DATE_CUR  \n",
      "0           GE50  01JUL17  \n",
      "1             PS  01JUL17  \n",
      "2           GE50  01JUL17  \n",
      "3           GE50  01JUL17  \n",
      "4             PS  01JUL17  \n",
      "\n",
      "[5 rows x 25 columns]\n",
      "     STNAM  FIPST   LEAID ST_LEAID             LEANM  ALL_COHORT_1617  \\\n",
      "0  ALABAMA      1  100005   AL-101  Albertville City              311   \n",
      "1  ALABAMA      1  100006   AL-048   Marshall County              431   \n",
      "2  ALABAMA      1  100007   AL-158       Hoover City             1153   \n",
      "3  ALABAMA      1  100008   AL-169      Madison City              861   \n",
      "4  ALABAMA      1  100011   AL-167        Leeds City              110   \n",
      "\n",
      "  ALL_RATE_1617  MAM_COHORT_1617 MAM_RATE_1617  MAS_COHORT_1617  ...  \\\n",
      "0            93              NaN           NaN              2.0  ...   \n",
      "1            90              NaN           NaN              1.0  ...   \n",
      "2            93              NaN           NaN             60.0  ...   \n",
      "3            97              NaN           NaN             60.0  ...   \n",
      "4          GE95              NaN           NaN              1.0  ...   \n",
      "\n",
      "  MTR_RATE_1617  MWH_COHORT_1617 MWH_RATE_1617  CWD_COHORT_1617 CWD_RATE_1617  \\\n",
      "0            PS            199.0         90-94              NaN           NaN   \n",
      "1            PS            356.0            90              NaN           NaN   \n",
      "2          GE90            682.0            95              NaN           NaN   \n",
      "3          GE80            544.0            97              NaN           NaN   \n",
      "4          GE50             55.0         80-89              NaN           NaN   \n",
      "\n",
      "   ECD_COHORT_1617 ECD_RATE_1617  LEP_COHORT_1617 LEP_RATE_1617  DATE_CUR  \n",
      "0              NaN           NaN              NaN           NaN   17AUG18  \n",
      "1              NaN           NaN              NaN           NaN   17AUG18  \n",
      "2              NaN           NaN              NaN           NaN   17AUG18  \n",
      "3              NaN           NaN              NaN           NaN   17AUG18  \n",
      "4              NaN           NaN              NaN           NaN   17AUG18  \n",
      "\n",
      "[5 rows x 26 columns]\n",
      "     STNAM  FIPST   LEAID ST_LEAID             LEANM  ALL_COHORT_1718  \\\n",
      "0  ALABAMA      1  100005   AL-101  Albertville City              312   \n",
      "1  ALABAMA      1  100006   AL-048   Marshall County              416   \n",
      "2  ALABAMA      1  100007   AL-158       Hoover City             1120   \n",
      "3  ALABAMA      1  100008   AL-169      Madison City              923   \n",
      "4  ALABAMA      1  100011   AL-167        Leeds City              128   \n",
      "\n",
      "  ALL_RATE_1718  MAM_COHORT_1718 MAM_RATE_1718  MAS_COHORT_1718  ...  \\\n",
      "0            94              NaN           NaN              2.0  ...   \n",
      "1            91              3.0            PS              3.0  ...   \n",
      "2            94              NaN           NaN             73.0  ...   \n",
      "3            96              3.0            PS             76.0  ...   \n",
      "4          GE95              NaN           NaN              2.0  ...   \n",
      "\n",
      "  CWD_RATE_1718  ECD_COHORT_1718 ECD_RATE_1718  FCS_COHORT_1718 FCS_RATE_1718  \\\n",
      "0          GE50             93.0         80-84              NaN           NaN   \n",
      "1         70-79            249.0         85-89              2.0            PS   \n",
      "2         60-69            234.0         80-84              2.0            PS   \n",
      "3         75-79            159.0         85-89              1.0            PS   \n",
      "4          GE50             53.0          GE90              1.0            PS   \n",
      "\n",
      "   HOM_COHORT_1718 HOM_RATE_1718  LEP_COHORT_1718 LEP_RATE_1718  DATE_CUR  \n",
      "0              2.0            PS             22.0         60-79   23SEP19  \n",
      "1             23.0          GE80             11.0          GE50   23SEP19  \n",
      "2              7.0          GE50              9.0          LT50   23SEP19  \n",
      "3              9.0          GE50             13.0          GE50   23SEP19  \n",
      "4              4.0            PS              1.0            PS   23SEP19  \n",
      "\n",
      "[5 rows x 30 columns]\n",
      "  SCHOOL_YEAR    STNAM  FIPST   LEAID ST_LEAID             LEANM CATEGORY  \\\n",
      "0   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      ALL   \n",
      "1   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      CWD   \n",
      "2   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      ECD   \n",
      "3   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      HOM   \n",
      "4   2018-2019  ALABAMA      1  100005   AL-101  Albertville City      LEP   \n",
      "\n",
      "   COHORT   RATE DATE_CUR  \n",
      "0     375     94  24JUL20  \n",
      "1      19   GE80  24JUL20  \n",
      "2     114  90-94  24JUL20  \n",
      "3       7   LT50  24JUL20  \n",
      "4      67  75-79  24JUL20  \n",
      "  SCHOOL_YEAR    STNAM  FIPST   LEAID ST_LEAID             LEANM CATEGORY  \\\n",
      "0   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      ALL   \n",
      "1   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      CWD   \n",
      "2   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      ECD   \n",
      "3   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      FCS   \n",
      "4   2019-2020  ALABAMA      1  100005   AL-101  Albertville City      HOM   \n",
      "\n",
      "   COHORT   RATE DATE_CUR  \n",
      "0     347     93  19MAY21  \n",
      "1      20  60-79  19MAY21  \n",
      "2      97  90-94  19MAY21  \n",
      "3       2     PS  19MAY21  \n",
      "4       2     PS  19MAY21  \n",
      "  SCHOOL_YEAR    STNAM  FIPST   LEAID ST_LEAID             LEANM CATEGORY  \\\n",
      "0   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      ALL   \n",
      "1   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      CWD   \n",
      "2   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      ECD   \n",
      "3   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      HOM   \n",
      "4   2020-2021  ALABAMA      1  100005   AL-101  Albertville City      LEP   \n",
      "\n",
      "   COHORT   RATE DATE_CUR  \n",
      "0     385     93  25MAY22  \n",
      "1      20  60-79  25MAY22  \n",
      "2     174  90-94  25MAY22  \n",
      "3       2     PS  25MAY22  \n",
      "4      57  80-89  25MAY22  \n"
     ]
    }
   ],
   "source": [
    "#Extracting\n",
    "# src/data/extract_data.py\n",
    "\n",
    "def extract_data(file_paths):\n",
    "    \"\"\"Extract data from multiple CSV files.\n",
    "\n",
    "    Parameters:\n",
    "    - file_paths (list of str): A list of paths to the CSV files.\n",
    "\n",
    "    Returns:\n",
    "    - list of pd.DataFrame: A list of the extracted data as pandas DataFrames.\n",
    "    \"\"\"\n",
    "    dataframes = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "    return dataframes\n",
    "\n",
    "file_paths = [\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2015-16.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2016-17.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2017-18.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2018-19-long.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2019-20-long.csv\",\n",
    "    r\"C:\\Users\\user\\Desktop\\StateEdFundingImpact\\data\\EdFacts\\acgr-lea-sy2020-21-long.csv\"\n",
    "]\n",
    "dfs = extract_data(file_paths)\n",
    "\n",
    "for df in dfs:\n",
    "    print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21052501",
   "metadata": {},
   "source": [
    "<!DOCTYPE html>\n",
    "<body>\n",
    "<h1 style=\"text-align: center;\">Streamlined Approach to Cleaning Educational Data</h1>\n",
    "\n",
    "<h3>Overview</h3>\n",
    "<p>In preparing the EDFacts educational data for comprehensive analysis, our approach was guided by the goal of ensuring data usability and integrity across all available years. Contrary to initial expectations, the distinction between pre-2018 and post-2018 datasets did not necessitate a significantly bifurcated cleaning strategy. Instead, we implemented a streamlined process that effectively addressed the nuances of the entire dataset, reinforcing our commitment to analytical precision and data consistency.</p>\n",
    "\n",
    "<h3>Key Steps in Data Preparation</h3>\n",
    "\n",
    "<strong>Data Extraction and Transformation:</strong>\n",
    "<p>Our first step involved extracting essential information and transforming the data into a long format, which enhanced our ability to manipulate and analyze the information at a granular level. This transformation was crucial for simplifying the datasets into a manageable structure conducive to in-depth examination.</p>\n",
    "\n",
    "<strong>Normalization and Aggregation:</strong>\n",
    "<p>We normalized rate data, converting various representations into a standardized numeric format to address the presence of rate ranges and specific codes. This uniformity allowed for comparative analyses across different states. Additionally, we aggregated the data by state, summarizing cohort sizes and average graduation rates, which was instrumental in comparing educational outcomes and understanding trends and patterns.</p>\n",
    "\n",
    "<h3>Consistent Cleaning Logic Across Years</h3>\n",
    "<p>Despite initial plans for a two-phase approach due to anticipated variations in data structure and reporting standards post-2018, our cleaning process remained largely consistent across all years. The minor adjustments made for post-2018 data did not significantly alter our overall strategy, allowing us to maintain a uniform analytical framework. This consistency ensures that our analysis is based on harmonized datasets, enabling us to draw meaningful insights into the impact of state funding and other factors on graduation outcomes—a key measure of educational success.</p>\n",
    "\n",
    "<h3>Conclusion</h3>\n",
    "<p>Our streamlined data cleaning process underscores the importance of flexibility and precision in handling educational data. By adapting our methodologies to the characteristics of the dataset as a whole, rather than imposing arbitrary divisions, we have laid a robust foundation for subsequent analyses. This approach allows us to explore the evolving landscape of educational data with an analytical lens that is both comprehensive and current, ensuring that our insights remain relevant and actionable.</p>\n",
    "\n",
    "</body>\n",
    "</html>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bce6f869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract data from the specified file paths\n",
    "state_grads_dataframes = extract_data(file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8309450",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dfs_2015_2021 = [clean_pre_18(df) if index < 3 else clean_post_18(df) for index, df in enumerate(dfs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf7e1cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         52 non-null     object \n",
      " 1   COHORT        52 non-null     object \n",
      " 2   PERCENT_RATE  52 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n",
      "\n",
      "\n",
      "DataFrame 1:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50 entries, 0 to 49\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         50 non-null     object \n",
      " 1   COHORT        50 non-null     object \n",
      " 2   PERCENT_RATE  50 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n",
      "\n",
      "\n",
      "DataFrame 2:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52 entries, 0 to 51\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         52 non-null     object \n",
      " 1   COHORT        52 non-null     object \n",
      " 2   PERCENT_RATE  52 non-null     float64\n",
      "dtypes: float64(1), object(2)\n",
      "memory usage: 1.3+ KB\n",
      "\n",
      "\n",
      "DataFrame 3:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51 entries, 2018-2019 to 2018-2019\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         51 non-null     object \n",
      " 1   COHORT        51 non-null     int64  \n",
      " 2   RATE_NUMERIC  51 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.6+ KB\n",
      "\n",
      "\n",
      "DataFrame 4:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 51 entries, 2019-2020 to 2019-2020\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         51 non-null     object \n",
      " 1   COHORT        51 non-null     int64  \n",
      " 2   RATE_NUMERIC  51 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.6+ KB\n",
      "\n",
      "\n",
      "DataFrame 5:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 50 entries, 2020-2021 to 2020-2021\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   STATE         50 non-null     object \n",
      " 1   COHORT        50 non-null     int64  \n",
      " 2   RATE_NUMERIC  50 non-null     float64\n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 1.6+ KB\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checking clean\n",
    "for index, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    print(f\"DataFrame {index}:\")\n",
    "    df.info()\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "54cb78e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0 head:\n",
      "DATA_TYPE                       STATE    COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                  \n",
      "2015-16                       ALABAMA  145983.0     76.378635\n",
      "2015-16                        ALASKA   25039.0     62.145089\n",
      "2015-16                       ARIZONA  202193.0     65.798584\n",
      "2015-16                      ARKANSAS   94906.0     76.651163\n",
      "2015-16      BUREAU OF INDIAN AFFAIRS    6772.0     69.043814 \n",
      "\n",
      "DataFrame 1 head:\n",
      "DATA_TYPE                       STATE    COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                  \n",
      "2016-17                       ALABAMA  110458.0     81.771401\n",
      "2016-17                        ALASKA   25788.0     63.026316\n",
      "2016-17                       ARIZONA  204878.0     64.633005\n",
      "2016-17                      ARKANSAS  100439.0     77.265913\n",
      "2016-17      BUREAU OF INDIAN AFFAIRS    9163.0     58.681579 \n",
      "\n",
      "DataFrame 2 head:\n",
      "DATA_TYPE                         STATE    COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                    \n",
      "2017-18                         ALABAMA  141949.0     77.201247\n",
      "2017-18                          ALASKA   26634.0     63.012245\n",
      "2017-18                         ARIZONA  217413.0     65.936614\n",
      "2017-18                        ARKANSAS  102892.0     75.852765\n",
      "2017-18      BUREAU OF INDIAN EDUCATION    9634.0     59.637056 \n",
      "\n",
      "DataFrame 3 head:\n",
      "                                  STATE  COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                  \n",
      "2018-2019                       ALABAMA  133900     78.639080\n",
      "2018-2019                        ALASKA   26166     64.489540\n",
      "2018-2019                       ARIZONA  220323     65.405128\n",
      "2018-2019                      ARKANSAS  107551     74.131542\n",
      "2018-2019    BUREAU OF INDIAN EDUCATION    8966     60.745238 \n",
      "\n",
      "DataFrame 4 head:\n",
      "                                  STATE  COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                                  \n",
      "2019-2020                       ALABAMA  136374     78.251689\n",
      "2019-2020                        ALASKA   25445     64.143154\n",
      "2019-2020                       ARIZONA  230145     64.288913\n",
      "2019-2020                      ARKANSAS  109168     74.784965\n",
      "2019-2020    BUREAU OF INDIAN EDUCATION    9410     61.677249 \n",
      "\n",
      "DataFrame 5 head:\n",
      "                  STATE   COHORT  PERCENT_RATE\n",
      "SCHOOL_YEAR                                   \n",
      "2020-2021       ALABAMA   134727     78.340782\n",
      "2020-2021        ALASKA    24658     63.096234\n",
      "2020-2021       ARIZONA   229510     63.609646\n",
      "2020-2021      ARKANSAS   105360     74.467483\n",
      "2020-2021    CALIFORNIA  1285025     75.479113 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "school_years_pre_18 = ['2015-16', '2016-17', '2017-18']\n",
    "\n",
    "for index, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    if index < 3:  # For pre-2018 DataFrames\n",
    "        df['SCHOOL_YEAR'] = school_years_pre_18[index]\n",
    "\n",
    "        # setting school year as index for 2015-2017 school years to match post 2018 sy's\n",
    "\n",
    "for i in range(3):  # This targets only the first three DataFrames\n",
    "    # Assuming 'SCHOOL_YEAR' is a column that needs to be set as the index for these DataFrames\n",
    "    cleaned_dfs_2015_2021[i].set_index('SCHOOL_YEAR', inplace=True)\n",
    "\n",
    "# making sure column names match for post 2018\n",
    "for i, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    # Check if 'RATE_NUMERIC' column exists in the DataFrame\n",
    "    if 'RATE_NUMERIC' in df.columns:\n",
    "        # Rename 'RATE_NUMERIC' to 'PERCENT_RATE'\n",
    "        df.rename(columns={'RATE_NUMERIC': 'PERCENT_RATE'}, inplace=True)\n",
    "\n",
    "\n",
    "for index, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    print(f\"DataFrame {index} head:\")\n",
    "    print(df.head(), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74ace12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 1 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 2 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 3 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 4 is clean of BUREAU OF INDIAN EDUCATION\n",
      "DataFrame 5 is clean of BUREAU OF INDIAN EDUCATION\n"
     ]
    }
   ],
   "source": [
    "# dropping Bureau of Indian Education since there is not information for SY 2020-2021\n",
    "cleaned_dfs_2015_2021 = [\n",
    "    df.query(\"STATE != 'BUREAU OF INDIAN EDUCATION'\") \n",
    "    if 'STATE' in df.columns else df  # Check if 'STATE' column exists to avoid KeyError\n",
    "    for df in cleaned_dfs_2015_2021\n",
    "]\n",
    "for index, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    if 'STATE' in df.columns and 'BUREAU OF INDIAN EDUCATION' in df['STATE'].values:\n",
    "        print(f\"BUREAU OF INDIAN EDUCATION exists in DataFrame {index}\")\n",
    "    else:\n",
    "        print(f\"DataFrame {index} is clean of BUREAU OF INDIAN EDUCATION\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37353f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 0 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 1 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 2 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 3 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 4 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n",
      "DataFrame 5 columns: ['STATE', 'COHORT', 'PERCENT_RATE']\n"
     ]
    }
   ],
   "source": [
    "for i, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    print(f\"DataFrame {i} columns:\", df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb115e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, df in enumerate(cleaned_dfs_2015_2021):\n",
    "    \"\"\"\n",
    "    Renames columns in each DataFrame within cleaned_dfs_2015_2021 to include the full school year in their names.\n",
    "\n",
    "    This loop iterates through each DataFrame in the cleaned_dfs_2015_2021 list. For each DataFrame, it calculates the\n",
    "    start and end years based on the index and a base year of 2015. It then renames the 'COHORT' and 'PERCENT_RATE'\n",
    "    columns to 'Cohort_{start_year}_{end_year}' and 'Rate_{start_year}_{end_year}', respectively, to reflect the\n",
    "    specific school year the data pertains to. The renaming is done in-place, updating each DataFrame within the list.\n",
    "\n",
    "    Parameters:\n",
    "    - i: Index of the current DataFrame in the cleaned_dfs_2015_2021 list.\n",
    "    - df: The current DataFrame being processed.\n",
    "\n",
    "    Returns:\n",
    "    - None. The function directly modifies the DataFrames in the cleaned_dfs_2015_2021 list.\n",
    "    \"\"\"\n",
    "    start_year = 2015 + i\n",
    "    end_year = start_year + 1  # To get the format like 2015_2016\n",
    "    df.rename(columns={'COHORT': f'Cohort_{start_year}_{end_year}', 'PERCENT_RATE': f'Rate_{start_year}_{end_year}'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b504e3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Cohort_2015_2016  Rate_2015_2016 Cohort_2016_2017  Rate_2016_2017  \\\n",
      "STATE                                                                          \n",
      "ALABAMA            145983.0       76.378635         110458.0       81.771401   \n",
      "ALASKA              25039.0       62.145089          25788.0       63.026316   \n",
      "ARIZONA            202193.0       65.798584         204878.0       64.633005   \n",
      "ARKANSAS            94906.0       76.651163         100439.0       77.265913   \n",
      "CALIFORNIA        1305135.0       76.375773        1256965.0       76.089526   \n",
      "\n",
      "           Cohort_2017_2018  Rate_2017_2018  Cohort_2018_2019  Rate_2018_2019  \\\n",
      "STATE                                                                           \n",
      "ALABAMA            141949.0       77.201247          133900.0       78.639080   \n",
      "ALASKA              26634.0       63.012245           26166.0       64.489540   \n",
      "ARIZONA            217413.0       65.936614          220323.0       65.405128   \n",
      "ARKANSAS           102892.0       75.852765          107551.0       74.131542   \n",
      "CALIFORNIA        1312181.0       74.947489         1291970.0       75.708344   \n",
      "\n",
      "            Cohort_2019_2020  Rate_2019_2020  Cohort_2020_2021  Rate_2020_2021  \n",
      "STATE                                                                           \n",
      "ALABAMA             136374.0       78.251689          134727.0       78.340782  \n",
      "ALASKA               25445.0       64.143154           24658.0       63.096234  \n",
      "ARIZONA             230145.0       64.288913          229510.0       63.609646  \n",
      "ARKANSAS            109168.0       74.784965          105360.0       74.467483  \n",
      "CALIFORNIA         1285366.0       75.111411         1285025.0       75.479113  \n"
     ]
    }
   ],
   "source": [
    "def merge_dataframes(cleaned_dfs):\n",
    "    \"\"\"\n",
    "    Merges a list of DataFrames into a single DataFrame.\n",
    "\n",
    "    This function initializes the merged DataFrame with the first DataFrame in the provided list.\n",
    "    It then iteratively merges each subsequent DataFrame into this initial DataFrame based on the 'STATE' column.\n",
    "    The merge is done using an outer join to ensure all data from each state is retained, even if some states\n",
    "    are missing from some DataFrames. The result is a comprehensive DataFrame that combines all the provided\n",
    "    DataFrames' information.\n",
    "\n",
    "    Parameters:\n",
    "    - cleaned_dfs (list of pd.DataFrame): A list of cleaned DataFrames ready to be merged. Each DataFrame\n",
    "      must contain a 'STATE' column as the key for merging.\n",
    "\n",
    "    Returns:\n",
    "    - pd.DataFrame: A single DataFrame resulting from the outer merge of all DataFrames in the input list.\n",
    "    \"\"\"\n",
    "    merged_state_grads_df = cleaned_dfs[0]\n",
    "\n",
    "    for df in cleaned_dfs[1:]:\n",
    "        merged_state_grads_df = pd.merge(merged_state_grads_df, df, on=\"STATE\", how=\"outer\")\n",
    "\n",
    "    # Set 'STATE' column as index\n",
    "    merged_state_grads_df.set_index('STATE', inplace=True)\n",
    "\n",
    "    return merged_state_grads_df\n",
    "\n",
    "# Usage\n",
    "merged_state_grads_df = merge_dataframes(cleaned_dfs_2015_2021)\n",
    "\n",
    "# Filtering out \"Bureau of Indian Affairs\"\n",
    "merged_state_grads_df = merged_state_grads_df[merged_state_grads_df.index != 'BUREAU OF INDIAN AFFAIRS']\n",
    "\n",
    "# Print to see if everything looks good\n",
    "print(merged_state_grads_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f86887a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ydata-profiling in c:\\users\\user\\anaconda3\\lib\\site-packages (4.6.5)\n",
      "Requirement already satisfied: scipy<1.12,>=1.4.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.11.1)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (2.0.3)\n",
      "Requirement already satisfied: matplotlib<3.9,>=3.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (3.7.2)\n",
      "Requirement already satisfied: pydantic>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (2.6.3)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (6.0)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (3.1.2)\n",
      "Requirement already satisfied: visions[type_image_path]==0.7.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.7.5)\n",
      "Requirement already satisfied: numpy<1.26,>=1.16.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.24.3)\n",
      "Requirement already satisfied: htmlmin==0.1.12 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.1.12)\n",
      "Requirement already satisfied: phik<0.13,>=0.11.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.12.4)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (2.31.0)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (4.65.0)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.12.2)\n",
      "Requirement already satisfied: multimethod<2,>=1.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.11.2)\n",
      "Requirement already satisfied: statsmodels<1,>=0.13.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.14.0)\n",
      "Requirement already satisfied: typeguard<5,>=4.1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (4.1.5)\n",
      "Requirement already satisfied: imagehash==4.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (4.3.1)\n",
      "Requirement already satisfied: wordcloud>=1.9.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.9.3)\n",
      "Requirement already satisfied: dacite>=1.8 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (1.8.1)\n",
      "Requirement already satisfied: numba<0.59.0,>=0.56.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from ydata-profiling) (0.57.1)\n",
      "Requirement already satisfied: PyWavelets in c:\\users\\user\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling) (1.4.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\user\\anaconda3\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling) (9.4.0)\n",
      "Requirement already satisfied: attrs>=19.3.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (22.1.0)\n",
      "Requirement already satisfied: networkx>=2.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (3.1)\n",
      "Requirement already satisfied: tangled-up-in-unicode>=0.0.4 in c:\\users\\user\\anaconda3\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (23.1)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\user\\anaconda3\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling) (2.8.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from numba<0.59.0,>=0.56.0->ydata-profiling) (0.40.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling) (2023.3)\n",
      "Requirement already satisfied: joblib>=0.14.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from phik<0.13,>=0.11.1->ydata-profiling) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=2->ydata-profiling) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.3 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=2->ydata-profiling) (2.16.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from pydantic>=2->ydata-profiling) (4.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\anaconda3\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling) (2023.7.22)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from statsmodels<1,>=0.13.2->ydata-profiling) (0.5.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\user\\anaconda3\\lib\\site-packages (from tqdm<5,>=4.48.2->ydata-profiling) (0.4.6)\n",
      "Requirement already satisfied: six in c:\\users\\user\\anaconda3\\lib\\site-packages (from patsy>=0.5.2->statsmodels<1,>=0.13.2->ydata-profiling) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install ydata-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a992575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "state_grads_profile = ProfileReport(merged_state_grads_df, title=\"Profile Report\", explorative=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d26e2c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44135a964f8842cfa8b329d97b6866d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cbf51299c0b4aea922ee930f733283a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd21b94f3fb47f0b03b59d05b47a4db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render widgets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort_2015_2016</th>\n",
       "      <th>Rate_2015_2016</th>\n",
       "      <th>Cohort_2016_2017</th>\n",
       "      <th>Rate_2016_2017</th>\n",
       "      <th>Cohort_2017_2018</th>\n",
       "      <th>Rate_2017_2018</th>\n",
       "      <th>Cohort_2018_2019</th>\n",
       "      <th>Rate_2018_2019</th>\n",
       "      <th>Cohort_2019_2020</th>\n",
       "      <th>Rate_2019_2020</th>\n",
       "      <th>Cohort_2020_2021</th>\n",
       "      <th>Rate_2020_2021</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ALABAMA</th>\n",
       "      <td>145983.0</td>\n",
       "      <td>76.378635</td>\n",
       "      <td>110458.0</td>\n",
       "      <td>81.771401</td>\n",
       "      <td>141949.0</td>\n",
       "      <td>77.201247</td>\n",
       "      <td>133900.0</td>\n",
       "      <td>78.639080</td>\n",
       "      <td>136374.0</td>\n",
       "      <td>78.251689</td>\n",
       "      <td>134727.0</td>\n",
       "      <td>78.340782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ALASKA</th>\n",
       "      <td>25039.0</td>\n",
       "      <td>62.145089</td>\n",
       "      <td>25788.0</td>\n",
       "      <td>63.026316</td>\n",
       "      <td>26634.0</td>\n",
       "      <td>63.012245</td>\n",
       "      <td>26166.0</td>\n",
       "      <td>64.489540</td>\n",
       "      <td>25445.0</td>\n",
       "      <td>64.143154</td>\n",
       "      <td>24658.0</td>\n",
       "      <td>63.096234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARIZONA</th>\n",
       "      <td>202193.0</td>\n",
       "      <td>65.798584</td>\n",
       "      <td>204878.0</td>\n",
       "      <td>64.633005</td>\n",
       "      <td>217413.0</td>\n",
       "      <td>65.936614</td>\n",
       "      <td>220323.0</td>\n",
       "      <td>65.405128</td>\n",
       "      <td>230145.0</td>\n",
       "      <td>64.288913</td>\n",
       "      <td>229510.0</td>\n",
       "      <td>63.609646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ARKANSAS</th>\n",
       "      <td>94906.0</td>\n",
       "      <td>76.651163</td>\n",
       "      <td>100439.0</td>\n",
       "      <td>77.265913</td>\n",
       "      <td>102892.0</td>\n",
       "      <td>75.852765</td>\n",
       "      <td>107551.0</td>\n",
       "      <td>74.131542</td>\n",
       "      <td>109168.0</td>\n",
       "      <td>74.784965</td>\n",
       "      <td>105360.0</td>\n",
       "      <td>74.467483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CALIFORNIA</th>\n",
       "      <td>1305135.0</td>\n",
       "      <td>76.375773</td>\n",
       "      <td>1256965.0</td>\n",
       "      <td>76.089526</td>\n",
       "      <td>1312181.0</td>\n",
       "      <td>74.947489</td>\n",
       "      <td>1291970.0</td>\n",
       "      <td>75.708344</td>\n",
       "      <td>1285366.0</td>\n",
       "      <td>75.111411</td>\n",
       "      <td>1285025.0</td>\n",
       "      <td>75.479113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>COLORADO</th>\n",
       "      <td>170104.0</td>\n",
       "      <td>66.989005</td>\n",
       "      <td>172656.0</td>\n",
       "      <td>67.217416</td>\n",
       "      <td>182296.0</td>\n",
       "      <td>67.019502</td>\n",
       "      <td>185387.0</td>\n",
       "      <td>67.832444</td>\n",
       "      <td>186766.0</td>\n",
       "      <td>67.660865</td>\n",
       "      <td>188020.0</td>\n",
       "      <td>67.560170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CONNECTICUT</th>\n",
       "      <td>111552.0</td>\n",
       "      <td>73.430323</td>\n",
       "      <td>112344.0</td>\n",
       "      <td>74.784434</td>\n",
       "      <td>109143.0</td>\n",
       "      <td>74.230686</td>\n",
       "      <td>114230.0</td>\n",
       "      <td>75.285037</td>\n",
       "      <td>114442.0</td>\n",
       "      <td>74.588266</td>\n",
       "      <td>110921.0</td>\n",
       "      <td>75.720313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DELAWARE</th>\n",
       "      <td>24280.0</td>\n",
       "      <td>73.600575</td>\n",
       "      <td>24843.0</td>\n",
       "      <td>75.322581</td>\n",
       "      <td>25004.0</td>\n",
       "      <td>74.258883</td>\n",
       "      <td>24086.0</td>\n",
       "      <td>74.136364</td>\n",
       "      <td>23753.0</td>\n",
       "      <td>73.773333</td>\n",
       "      <td>28858.0</td>\n",
       "      <td>69.682377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DISTRICT OF COLUMBIA</th>\n",
       "      <td>14734.0</td>\n",
       "      <td>68.418750</td>\n",
       "      <td>14841.0</td>\n",
       "      <td>69.544304</td>\n",
       "      <td>15052.0</td>\n",
       "      <td>64.547872</td>\n",
       "      <td>15438.0</td>\n",
       "      <td>64.542453</td>\n",
       "      <td>14213.0</td>\n",
       "      <td>68.098039</td>\n",
       "      <td>13356.0</td>\n",
       "      <td>66.658654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FLORIDA</th>\n",
       "      <td>536648.0</td>\n",
       "      <td>72.603242</td>\n",
       "      <td>556875.0</td>\n",
       "      <td>73.404075</td>\n",
       "      <td>575615.0</td>\n",
       "      <td>76.652012</td>\n",
       "      <td>586513.0</td>\n",
       "      <td>77.505170</td>\n",
       "      <td>585167.0</td>\n",
       "      <td>81.488355</td>\n",
       "      <td>584906.0</td>\n",
       "      <td>81.109353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Cohort_2015_2016  Rate_2015_2016 Cohort_2016_2017  \\\n",
       "STATE                                                                    \n",
       "ALABAMA                      145983.0       76.378635         110458.0   \n",
       "ALASKA                        25039.0       62.145089          25788.0   \n",
       "ARIZONA                      202193.0       65.798584         204878.0   \n",
       "ARKANSAS                      94906.0       76.651163         100439.0   \n",
       "CALIFORNIA                  1305135.0       76.375773        1256965.0   \n",
       "COLORADO                     170104.0       66.989005         172656.0   \n",
       "CONNECTICUT                  111552.0       73.430323         112344.0   \n",
       "DELAWARE                      24280.0       73.600575          24843.0   \n",
       "DISTRICT OF COLUMBIA          14734.0       68.418750          14841.0   \n",
       "FLORIDA                      536648.0       72.603242         556875.0   \n",
       "\n",
       "                      Rate_2016_2017 Cohort_2017_2018  Rate_2017_2018  \\\n",
       "STATE                                                                   \n",
       "ALABAMA                    81.771401         141949.0       77.201247   \n",
       "ALASKA                     63.026316          26634.0       63.012245   \n",
       "ARIZONA                    64.633005         217413.0       65.936614   \n",
       "ARKANSAS                   77.265913         102892.0       75.852765   \n",
       "CALIFORNIA                 76.089526        1312181.0       74.947489   \n",
       "COLORADO                   67.217416         182296.0       67.019502   \n",
       "CONNECTICUT                74.784434         109143.0       74.230686   \n",
       "DELAWARE                   75.322581          25004.0       74.258883   \n",
       "DISTRICT OF COLUMBIA       69.544304          15052.0       64.547872   \n",
       "FLORIDA                    73.404075         575615.0       76.652012   \n",
       "\n",
       "                      Cohort_2018_2019  Rate_2018_2019  Cohort_2019_2020  \\\n",
       "STATE                                                                      \n",
       "ALABAMA                       133900.0       78.639080          136374.0   \n",
       "ALASKA                         26166.0       64.489540           25445.0   \n",
       "ARIZONA                       220323.0       65.405128          230145.0   \n",
       "ARKANSAS                      107551.0       74.131542          109168.0   \n",
       "CALIFORNIA                   1291970.0       75.708344         1285366.0   \n",
       "COLORADO                      185387.0       67.832444          186766.0   \n",
       "CONNECTICUT                   114230.0       75.285037          114442.0   \n",
       "DELAWARE                       24086.0       74.136364           23753.0   \n",
       "DISTRICT OF COLUMBIA           15438.0       64.542453           14213.0   \n",
       "FLORIDA                       586513.0       77.505170          585167.0   \n",
       "\n",
       "                      Rate_2019_2020  Cohort_2020_2021  Rate_2020_2021  \n",
       "STATE                                                                   \n",
       "ALABAMA                    78.251689          134727.0       78.340782  \n",
       "ALASKA                     64.143154           24658.0       63.096234  \n",
       "ARIZONA                    64.288913          229510.0       63.609646  \n",
       "ARKANSAS                   74.784965          105360.0       74.467483  \n",
       "CALIFORNIA                 75.111411         1285025.0       75.479113  \n",
       "COLORADO                   67.660865          188020.0       67.560170  \n",
       "CONNECTICUT                74.588266          110921.0       75.720313  \n",
       "DELAWARE                   73.773333           28858.0       69.682377  \n",
       "DISTRICT OF COLUMBIA       68.098039           13356.0       66.658654  \n",
       "FLORIDA                    81.488355          584906.0       81.109353  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cohort_2015_2016</th>\n",
       "      <th>Rate_2015_2016</th>\n",
       "      <th>Cohort_2016_2017</th>\n",
       "      <th>Rate_2016_2017</th>\n",
       "      <th>Cohort_2017_2018</th>\n",
       "      <th>Rate_2017_2018</th>\n",
       "      <th>Cohort_2018_2019</th>\n",
       "      <th>Rate_2018_2019</th>\n",
       "      <th>Cohort_2019_2020</th>\n",
       "      <th>Rate_2019_2020</th>\n",
       "      <th>Cohort_2020_2021</th>\n",
       "      <th>Rate_2020_2021</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>STATE</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TENNESSEE</th>\n",
       "      <td>170400.0</td>\n",
       "      <td>79.570556</td>\n",
       "      <td>177993.0</td>\n",
       "      <td>79.951268</td>\n",
       "      <td>184127.0</td>\n",
       "      <td>78.232572</td>\n",
       "      <td>187388.0</td>\n",
       "      <td>78.328471</td>\n",
       "      <td>186639.0</td>\n",
       "      <td>77.987254</td>\n",
       "      <td>184722.0</td>\n",
       "      <td>76.653326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEXAS</th>\n",
       "      <td>905626.0</td>\n",
       "      <td>75.788306</td>\n",
       "      <td>935834.0</td>\n",
       "      <td>75.849329</td>\n",
       "      <td>1002162.0</td>\n",
       "      <td>75.516783</td>\n",
       "      <td>1058931.0</td>\n",
       "      <td>75.568652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1080619.0</td>\n",
       "      <td>75.494268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UTAH</th>\n",
       "      <td>109404.0</td>\n",
       "      <td>71.031729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239013.0</td>\n",
       "      <td>73.716867</td>\n",
       "      <td>243149.0</td>\n",
       "      <td>73.807322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VERMONT</th>\n",
       "      <td>16037.0</td>\n",
       "      <td>74.640244</td>\n",
       "      <td>15635.0</td>\n",
       "      <td>74.934263</td>\n",
       "      <td>15407.0</td>\n",
       "      <td>72.880952</td>\n",
       "      <td>14587.0</td>\n",
       "      <td>71.188636</td>\n",
       "      <td>15208.0</td>\n",
       "      <td>70.946903</td>\n",
       "      <td>15178.0</td>\n",
       "      <td>71.015695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIRGINIA</th>\n",
       "      <td>231038.0</td>\n",
       "      <td>73.828626</td>\n",
       "      <td>241885.0</td>\n",
       "      <td>74.142217</td>\n",
       "      <td>251452.0</td>\n",
       "      <td>73.750774</td>\n",
       "      <td>254039.0</td>\n",
       "      <td>73.750784</td>\n",
       "      <td>257399.0</td>\n",
       "      <td>75.097122</td>\n",
       "      <td>252753.0</td>\n",
       "      <td>75.766154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WASHINGTON</th>\n",
       "      <td>203730.0</td>\n",
       "      <td>70.319813</td>\n",
       "      <td>207249.0</td>\n",
       "      <td>70.672682</td>\n",
       "      <td>206645.0</td>\n",
       "      <td>74.427888</td>\n",
       "      <td>218063.0</td>\n",
       "      <td>71.171623</td>\n",
       "      <td>230876.0</td>\n",
       "      <td>70.743902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WEST VIRGINIA</th>\n",
       "      <td>49051.0</td>\n",
       "      <td>80.029091</td>\n",
       "      <td>56443.0</td>\n",
       "      <td>81.732342</td>\n",
       "      <td>57253.0</td>\n",
       "      <td>79.304487</td>\n",
       "      <td>43683.0</td>\n",
       "      <td>76.411003</td>\n",
       "      <td>51779.0</td>\n",
       "      <td>80.860248</td>\n",
       "      <td>50486.0</td>\n",
       "      <td>77.857143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WISCONSIN</th>\n",
       "      <td>160199.0</td>\n",
       "      <td>75.049941</td>\n",
       "      <td>160581.0</td>\n",
       "      <td>75.053253</td>\n",
       "      <td>166749.0</td>\n",
       "      <td>75.480577</td>\n",
       "      <td>166356.0</td>\n",
       "      <td>75.039695</td>\n",
       "      <td>164365.0</td>\n",
       "      <td>75.040860</td>\n",
       "      <td>163537.0</td>\n",
       "      <td>74.647480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WYOMING</th>\n",
       "      <td>18321.0</td>\n",
       "      <td>68.292411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18173.0</td>\n",
       "      <td>68.756410</td>\n",
       "      <td>18330.0</td>\n",
       "      <td>68.339662</td>\n",
       "      <td>18363.0</td>\n",
       "      <td>68.085106</td>\n",
       "      <td>18940.0</td>\n",
       "      <td>68.004219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PUERTO RICO</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>93148.0</td>\n",
       "      <td>68.375000</td>\n",
       "      <td>86383.0</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>79139.0</td>\n",
       "      <td>68.937500</td>\n",
       "      <td>75487.0</td>\n",
       "      <td>71.687500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Cohort_2015_2016  Rate_2015_2016 Cohort_2016_2017  \\\n",
       "STATE                                                             \n",
       "TENNESSEE             170400.0       79.570556         177993.0   \n",
       "TEXAS                 905626.0       75.788306         935834.0   \n",
       "UTAH                  109404.0       71.031729              NaN   \n",
       "VERMONT                16037.0       74.640244          15635.0   \n",
       "VIRGINIA              231038.0       73.828626         241885.0   \n",
       "WASHINGTON            203730.0       70.319813         207249.0   \n",
       "WEST VIRGINIA          49051.0       80.029091          56443.0   \n",
       "WISCONSIN             160199.0       75.049941         160581.0   \n",
       "WYOMING                18321.0       68.292411              NaN   \n",
       "PUERTO RICO                NaN             NaN              NaN   \n",
       "\n",
       "               Rate_2016_2017 Cohort_2017_2018  Rate_2017_2018  \\\n",
       "STATE                                                            \n",
       "TENNESSEE           79.951268         184127.0       78.232572   \n",
       "TEXAS               75.849329        1002162.0       75.516783   \n",
       "UTAH                      NaN              NaN             NaN   \n",
       "VERMONT             74.934263          15407.0       72.880952   \n",
       "VIRGINIA            74.142217         251452.0       73.750774   \n",
       "WASHINGTON          70.672682         206645.0       74.427888   \n",
       "WEST VIRGINIA       81.732342          57253.0       79.304487   \n",
       "WISCONSIN           75.053253         166749.0       75.480577   \n",
       "WYOMING                   NaN          18173.0       68.756410   \n",
       "PUERTO RICO               NaN          93148.0       68.375000   \n",
       "\n",
       "               Cohort_2018_2019  Rate_2018_2019  Cohort_2019_2020  \\\n",
       "STATE                                                               \n",
       "TENNESSEE              187388.0       78.328471          186639.0   \n",
       "TEXAS                 1058931.0       75.568652               NaN   \n",
       "UTAH                        NaN             NaN          239013.0   \n",
       "VERMONT                 14587.0       71.188636           15208.0   \n",
       "VIRGINIA               254039.0       73.750784          257399.0   \n",
       "WASHINGTON             218063.0       71.171623          230876.0   \n",
       "WEST VIRGINIA           43683.0       76.411003           51779.0   \n",
       "WISCONSIN              166356.0       75.039695          164365.0   \n",
       "WYOMING                 18330.0       68.339662           18363.0   \n",
       "PUERTO RICO             86383.0       68.000000           79139.0   \n",
       "\n",
       "               Rate_2019_2020  Cohort_2020_2021  Rate_2020_2021  \n",
       "STATE                                                            \n",
       "TENNESSEE           77.987254          184722.0       76.653326  \n",
       "TEXAS                     NaN         1080619.0       75.494268  \n",
       "UTAH                73.716867          243149.0       73.807322  \n",
       "VERMONT             70.946903           15178.0       71.015695  \n",
       "VIRGINIA            75.097122          252753.0       75.766154  \n",
       "WASHINGTON          70.743902               NaN             NaN  \n",
       "WEST VIRGINIA       80.860248           50486.0       77.857143  \n",
       "WISCONSIN           75.040860          163537.0       74.647480  \n",
       "WYOMING             68.085106           18940.0       68.004219  \n",
       "PUERTO RICO         68.937500           75487.0       71.687500  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d99476bfdc6477a9eba91dee076e9f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "state_grads_profile.to_widgets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e786614c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fa3620",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
